# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import xgboost as xgb


# Load the CSV data
df = pd.read_csv('USvideos.csv')

# Load the JSON data for category mapping
categories = pd.read_json('us_category_id.json')

# Merge the category information with your main data based on 'category_id' (if needed)
df = pd.merge(df, categories, left_on='category_id', right_on='id', how='left')

# Display the first few rows of the merged data to ensure it's loaded correctly
df.head()



# Convert date columns to datetime format
df['trending_date'] = pd.to_datetime(df['trending_date'], format='%y.%d.%m')
df['publish_time'] = pd.to_datetime(df['publish_time'])

# Handle missing values (fill with mean, median, or drop as appropriate)
df.fillna(df.mean(), inplace=True)

# Example of creating new features
df['views_7d_avg'] = df['views'].rolling(window=7).mean()

# Show the data after cleaning
df.head()



# Features (X) and target (y)
X = df[['views_7d_avg', 'comment_count', 'likes', 'dislikes']]  # Modify with relevant features
y = df['views']  # Target variable

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)



# Linear Regression model
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)

# Predictions
y_pred_linear = linear_model.predict(X_test)

# Evaluate the model
mse_linear = mean_squared_error(y_test, y_pred_linear)
r2_linear = r2_score(y_test, y_pred_linear)

print(f"Linear Regression - MSE: {mse_linear}, R2: {r2_linear}")



# XGBoost model
xg_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
xg_model.fit(X_train, y_train)

# Predictions
y_pred_xg = xg_model.predict(X_test)

# Evaluate the model
mse_xg = mean_squared_error(y_test, y_pred_xg)
r2_xg = r2_score(y_test, y_pred_xg)

print(f"XGBoost - MSE: {mse_xg}, R2: {r2_xg}")


# Print comparison of models
print(f"Linear Regression - MSE: {mse_linear}, R2: {r2_linear}")
print(f"XGBoost - MSE: {mse_xg}, R2: {r2_xg}")
# Feature importance for XGBoost
xgb.plot_importance(xg_model)
plt.show()
