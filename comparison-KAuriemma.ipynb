{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76208a37-5b6e-4f1b-971a-f60902215cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5024628-d399-4407-8893-24e4dfdafc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Metric  Linear Regression       XGBoost\n",
      "MSE     MSE       1.189364e+12  2.058264e+12\n",
      "R²       R²       9.705600e-01  9.490523e-01\n",
      "MAE     MAE       3.886054e+05  2.221251e+05\n",
      "RMSE   RMSE       1.090579e+06  1.434665e+06\n"
     ]
    }
   ],
   "source": [
    "# UNTUNED RESULTS\n",
    "# Load results from Linear Regression and XGBoost\n",
    "untunedlr_results = pd.read_csv('untunedlr_results.csv')\n",
    "untunedxgb_results = pd.read_csv('untunedxgb_results.csv')\n",
    "\n",
    "# Create a new DataFrame to compare models\n",
    "model_comparison_untuned = pd.DataFrame({\n",
    "    'Metric': ['MSE', 'R²', 'MAE', 'RMSE'],\n",
    "    'Linear Regression': untunedlr_results.iloc[0],  # Extracting the first row \n",
    "    'XGBoost': untunedxgb_results.iloc[0]  # Extracting the first row \n",
    "})\n",
    "\n",
    "# Display the comparison table\n",
    "print(model_comparison_untuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f34a1a02-0833-422b-a4de-8d7b4281bd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Metric  Linear Regression       XGBoost\n",
      "MSE     MSE       1.184753e+12  2.365999e+12\n",
      "R²       R²       9.706741e-01  9.414351e-01\n",
      "MAE     MAE       3.874768e+05  2.527203e+05\n",
      "RMSE   RMSE       1.088464e+06  1.538180e+06\n"
     ]
    }
   ],
   "source": [
    "# TUNED RESULTS\n",
    "# Load results from Linear Regression and XGBoost\n",
    "lr_results = pd.read_csv('lr_results.csv')\n",
    "xgb_results = pd.read_csv('xgb_results.csv')\n",
    "\n",
    "# Create a new DataFrame to compare models\n",
    "model_comparison_tuned = pd.DataFrame({\n",
    "    'Metric': ['MSE', 'R²', 'MAE', 'RMSE'],\n",
    "    'Linear Regression': lr_results.iloc[0],  # Extracting the first row of lr_results\n",
    "    'XGBoost': xgb_results.iloc[0]  # Extracting the first row of xgb_results\n",
    "})\n",
    "\n",
    "# Display the comparison table\n",
    "print(model_comparison_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c41c94d-18fe-44d6-b10a-6d9f3cd6cb27",
   "metadata": {},
   "source": [
    "#### Linear Regression\n",
    "##### Performance: The untuned and tuned Linear Regression models show similar performance, with minimal improvements after tuning (Ridge regression). The MSE remains relatively high, and the R² values are almost identical, indicating no significant improvement in predictive accuracy. Despite tuning, the model still struggles with large errors, as seen in both the MAE and RMSE values. These metrics suggest that the model's predictions have considerable deviation from the actual values, reflecting poor predictive accuracy.\n",
    "##### Limitations: Linear Regression assumes a linear relationship between the features and the target variable, which limits its ability to capture more complex, non-linear relationships in the data. In the case of viral YouTube videos, where trends can be highly volatile and non-linear, this assumption of linearity restricts the model’s performance. The lack of significant improvement after tuning further supports the notion that Linear Regression is not the most suitable model for this task.\n",
    "\n",
    "#### XGBoost\n",
    "##### Performance: XGBoost shows a modest improvement after tuning, with slightly lower MSE and a slightly higher R². However, even the untuned XGBoost model outperforms both the untuned and tuned Linear Regression models in terms of MSE, R², MAE, and RMSE. This suggests that XGBoost is better suited for capturing complex relationships in the data.\n",
    "##### Strengths: XGBoost excels at modeling non-linear patterns and complex interactions between features, making it more effective at predicting viral spikes in views, where trends are often unpredictable and non-linear. The model’s ability to adapt to these complexities gives it an edge over Linear Regression, which is constrained by simpler assumptions.\n",
    "##### Limitations: While XGBoost is effective at capturing non-linear relationships, the model is sensitive to hyperparameters and can be computationally expensive, especially on large datasets. It may also overfit, particularly when dealing with noisy or sparse data. Despite these limitations, XGBoost generally outperforms Linear Regression for this type of task, given its flexibility and ability to handle complex data patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c024e7e6-5346-4e88-b72a-aae18e3c0f1b",
   "metadata": {},
   "source": [
    "### Based on the analysis, Linear Regression achieves a higher R² and lower MSE, suggesting it explains the data better overall. However, XGBoost performs better in terms of MAE, indicating that its predictions are generally more accurate and with fewer large errors. While tuning does not drastically improve either model, XGBoost remains the more practical model for predicting viral YouTube views due to its ability to reduce larger errors in predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
